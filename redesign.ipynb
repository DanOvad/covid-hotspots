{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for preparing redesign of data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Libraries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_processing\n",
    "import plotting\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 1\n",
    "\n",
    "%aimport data_processing\n",
    "%aimport plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County GeoJson for polygons on choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Map of US counties\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    county_geojson = json.load(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/county_geojson.json','w') as fout:\n",
    "    json.dump(county_geojson,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/county_geojson.json','r') as fout:\n",
    "    county_geojson = json.load(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County Data\n",
    "This is where we import data from [New York Times GitHub page](https://github.com/nytimes/covid-19-data) to get county level coronavirus data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = time.strftime('%Y%m%d')\n",
    "filepath = f'data/covid_counties_{today}.csv'\n",
    "if path.exists(filepath):\n",
    "    print(\"Pulling from file.\")\n",
    "    df = pd.read_csv(filepath)\n",
    "else:\n",
    "    print(\"Pulling from github.\")\n",
    "    url = 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'\n",
    "    df = pd.read_csv(url)\n",
    "    df.to_csv(filepath)\n",
    "\n",
    "# Reassign our fips to be a string of length 5\n",
    "df['fipsnum'] = df['fips']\n",
    "df['fips'] = df['fipsnum'].astype(str).apply(lambda x: '0'+x[:4] if len(x) == 6 else x[:5])\n",
    "# Set date format\n",
    "df['date'] = pd.to_datetime(df['date'], format = '%Y-%m-%d')\n",
    "# Create log_deaths column\n",
    "df['log_deaths'] = np.log(df['deaths'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_processing.get_covid_county_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get State Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covid_state_data():\n",
    "    today = time.strftime('%Y%m%d')\n",
    "    filepath = f'data/covid_states_{today}.csv'\n",
    "    if path.exists(filepath):\n",
    "        print(\"Pulling from file.\")\n",
    "        covid_states_df = pd.read_csv(filepath)\n",
    "    else:\n",
    "        print(\"Pulling from Covid Tracking API\")\n",
    "        # Coronavirus data by state from covidtracking API\n",
    "        states_url = \"https://covidtracking.com/api/states/daily\"\n",
    "        r = requests.get(states_url)\n",
    "        covid_states_df = pd.DataFrame(r.json())\n",
    "        \n",
    "        # Set date as datetime format\n",
    "        covid_states_df['date'] = pd.to_datetime(covid_states_df.date, format=\"%Y%m%d\")\n",
    "        # set date to index\n",
    "        covid_states_df.set_index(keys='date',inplace=True)\n",
    "        covid_states_df.to_csv(filepath)\n",
    "            \n",
    "    return covid_states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_STATES_DF = data_processing.get_covid_state_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_STATES_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.choropleth_state_deaths_density(COVID_STATES_DF,'death')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_STATES_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_STATES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID_STATES_DF.loc['2020-08-26']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the unemployment data because it has the fips codes\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n",
    "                   dtype={\"fips\": str})\n",
    "df['prefix'] = [x[:2] for x in df['fips']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA-states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deaths = states_df.reset_index()\n",
    "################################################################################\n",
    "# Read in states data\n",
    "states = pd.read_csv('./data/tbl_states.csv')\n",
    "\n",
    "# Fix fips code to be a string, prefix 0 to single digit codes\n",
    "states['fips'] = states['fips'].astype(str).apply(lambda x: '0' + x if len(x) == 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, states, left_on='prefix', right_on='fips', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = states_df[['state','death','deathIncrease','positive','fips']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged = pd.merge(df, states, left_on='prefix', right_on='fips', how='outer')\n",
    "    # Rename convention\n",
    "merged.rename(columns={'fips_x': 'fips_co', 'fips_y':'fips_st'}, inplace=True)\n",
    "\n",
    "max_date = max(deaths['date'])\n",
    "deaths = deaths[deaths['date'] == max_date]\n",
    "\n",
    "final = pd.merge(merged, deaths, how='outer')\n",
    "final = final.drop(columns=['prefix'])\n",
    "\n",
    "# Create a log scale of lived in density\n",
    "final['logd'] = np.log(final['Lived'])\n",
    "\n",
    "# create a column for death_per_m\n",
    "x = final['death']*1000000 / final['Pop']\n",
    "final['death_per_m'] = x.copy()\n",
    "\n",
    "final['log_std_density'] = np.log(final['Standard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dates for Date Slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's datea\n",
    "date = time.strftime('%Y-%m-%d')\n",
    "# Set New York for state mask\n",
    "state = 'New York'\n",
    "\n",
    "# Only look at New York Dates\n",
    "state_mask = (df['state'] == state)\n",
    "\n",
    "# create today's date mask\n",
    "date_mask = (df['date'] == date)\n",
    "\n",
    "# Get min date from df\n",
    "min_date = int(time.mktime(df['date'].min().timetuple()))\n",
    "\n",
    "# Hardcode a start date\n",
    "start_date = '2020-03-01'\n",
    "start_date_int = int(time.mktime(datetime.datetime.strptime(start_date, '%Y-%m-%d').timetuple()))\n",
    "\n",
    "# Get max date from df\n",
    "max_date_int = int(time.mktime(df['date'].max().timetuple()))\n",
    "\n",
    "# Create a list of dates from max to min, going back 2 weeks each time\n",
    "date_list = range(max_date_int, start_date_int, -(14*24*60*60))\n",
    "date_dict = {day:time.strftime('%Y-%m-%d',time.localtime(day))  for day in date_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dict = data_processing.generate_slider_dates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date\n",
    "time.strftime('%Y-%m-%d', time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dash Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2020-08-26'\n",
    "date_mask = (df['date'] == date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = round(df[date_mask]['cases'].mean(),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(a.mean(),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB = pd.DataFrame(df.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcc.Store(id='store', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
